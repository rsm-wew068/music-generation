{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Sine wave generation and binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A - Sine Wave Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "To complete this part, install the required Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (installation process may be different on your system)\n",
    "# You don't need to use these libraries, so long as you implement the specified functions\n",
    "# !pip install numpy\n",
    "# !pip install scipy\n",
    "# !pip install IPython\n",
    "# !pip install glob\n",
    "# !pip install scikit-learn\n",
    "# !pip install mido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "from mido import MidiFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function that converts a musical note name to its corresponding frequency in Hertz (Hz)\n",
    "\n",
    "`note_name_to_frequency()`\n",
    "- **Input**: A string `note_name` combining a note (e.g., `'C'`, `'C#'`, `'D'`, `'D#'`, `'E'`, `'F'`, `'F#'`, `'G'`, `'G#'`, `'A'`, `'A#'`, `'B'`) and an octave number (`'0'` to `'10'`)\n",
    "- **Output**: A float representing the frequency in Hz\n",
    "- **Details**:\n",
    "  - Use A4 = 440 Hz as the reference frequency\n",
    "  - Frequencies double with each octave increase (e.g., A5 = 880 Hz) and halve with each decrease (e.g., A3 = 220 Hz)\n",
    "\n",
    "- **Examples**:\n",
    "  - `'A4'` → `440.0`\n",
    "  - `'A3'` → `220.0`\n",
    "  - `'G#4'` → `415.3047`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_name_to_frequency(note_name):\n",
    "    # Define the semitone offset from A for each note\n",
    "    note_to_semitone = {\n",
    "        'C': -9, 'C#': -8, 'D': -7, 'D#': -6,\n",
    "        'E': -5, 'F': -4, 'F#': -3, 'G': -2,\n",
    "        'G#': -1, 'A': 0, 'A#': 1, 'B': 2\n",
    "    }\n",
    "\n",
    "    # Extract note and octave from the note_name\n",
    "    if len(note_name) == 2:\n",
    "        note = note_name[0]\n",
    "        octave = int(note_name[1])\n",
    "    elif len(note_name) == 3:\n",
    "        note = note_name[:2]\n",
    "        octave = int(note_name[2])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid note name format\")\n",
    "\n",
    "    # Calculate the number of semitones from A4\n",
    "    semitone_diff = note_to_semitone[note] + (octave - 4) * 12\n",
    "\n",
    "    # Calculate frequency using the formula\n",
    "    frequency = 440.0 * (2 ** (semitone_diff / 12))\n",
    "\n",
    "    return round(frequency, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function that linearly decreases the amplitude of a given waveform\n",
    "\n",
    "`decrease_amplitude()`\n",
    "- **Inputs**:\n",
    "  - `audio`: A NumPy array representing the audio waveform at a sample rate of 44100 Hz\n",
    "- **Output**: A NumPy array representing the audio waveform at a sample rate of 44100 Hz\n",
    "- **Details**:\n",
    "  - The function must linearly decrease the amplitude of the input audio. The amplitude should start at 1 (full volume) and decrease gradually to 0 (silence) by the end of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrease_amplitude(audio):\n",
    "    # Generate a linear fade-out envelope from 1 to 0\n",
    "    fade_out = np.linspace(1, 0, num=len(audio))\n",
    "    \n",
    "    # Apply the fade-out to the audio waveform\n",
    "    faded_audio = audio * fade_out\n",
    "    \n",
    "    return faded_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a function that adds a delay effect to a given audio where the output is a combination of the original audio and a delayed audio\n",
    "\n",
    "`add_delay_effects()`  \n",
    "- **Inputs**:  \n",
    "  - `audio`: A NumPy array representing the audio waveform, sampled at 44,100 Hz\n",
    "- **Output**:  \n",
    "  - A NumPy array representing the modified audio waveform, sampled at 44,100 Hz\n",
    "- **Details**:\n",
    "  - The amplitude of the delayed audio should be 30% of the original audio's amplitude\n",
    "  - The amplitude of the original audio should be adjusted to 70% of the original audio's amplitude\n",
    "  - The output should combine the original audio (with the adjusted amplitude) with a delayed version of itself\n",
    "  - The delayed audio should be offset by 0.5 seconds behind the original audio\n",
    "\n",
    "- **Examples**:\n",
    "  - The provided files (input.wav and output.wav) provide examples of input and output audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can use these for visualization if you like, though the autograder won't use ipython\n",
    "\n",
    "# from IPython.display import Audio, display\n",
    "\n",
    "# print(\"Example Input Audio:\")\n",
    "# display(Audio(filename = \"input.wav\", rate=44100))\n",
    "\n",
    "# print(\"Example Output Audio:\")\n",
    "# display(Audio(filename = \"output.wav\", rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_delay_effects(audio):\n",
    "    sample_rate = 44100  # Hz\n",
    "    delay_seconds = 0.5\n",
    "    delay_samples = int(sample_rate * delay_seconds)\n",
    "    \n",
    "    # Create the delayed signal: same length as original + delay\n",
    "    delayed_signal = np.zeros(len(audio) + delay_samples)\n",
    "    \n",
    "    # Add the original signal scaled to 70%\n",
    "    delayed_signal[:len(audio)] += 0.7 * audio\n",
    "    \n",
    "    # Add the delayed signal scaled to 30%\n",
    "    delayed_signal[delay_samples:] += 0.3 * audio\n",
    "    \n",
    "    return delayed_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a function that concatenates a list of audio arrays sequentially and a function that mixes audio arrays by scaling and summing them, simulating simultaneous playback\n",
    "\n",
    "`concatenate_audio()`\n",
    "- **Input**:\n",
    "  - `list_of_your_audio`: A list of NumPy arrays (e.g., `[audio1, audio2]`), each representing audio at 44100 Hz\n",
    "- **Output**: A NumPy array of the concatenated audio\n",
    "- **Example**:\n",
    "  - If `audio1` is 2 seconds (88200 samples) and `audio2` is 1 second (44100 samples), the output is 3 seconds (132300 samples)\n",
    "\n",
    "`mix_audio()`\n",
    "- **Inputs**:\n",
    "  - `list_of_your_audio`: A list of NumPy arrays (e.g., `[audio1, audio2]`), all with the same length at 44100 Hz.\n",
    "  - `amplitudes`: A list of floats (e.g., `[0.2, 0.8]`) matching the length of `list_of_your_audio`\n",
    "- **Output**: A NumPy array representing the mixed audio\n",
    "- **Example**:\n",
    "  - If `audio1` and `audio2` are 2 seconds long, and `amplitudes = [0.2, 0.8]`, the output is `0.2 * audio1 + 0.8 * audio2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_audio(list_of_your_audio):\n",
    "    # Concatenate audio arrays one after another\n",
    "    return np.concatenate(list_of_your_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_audio(list_of_your_audio, amplitudes):\n",
    "    if len(list_of_your_audio) != len(amplitudes):\n",
    "        raise ValueError(\"The number of audio arrays must match the number of amplitude values.\")\n",
    "    \n",
    "    # Ensure all audio arrays are the same length\n",
    "    length = len(list_of_your_audio[0])\n",
    "    if not all(len(audio) == length for audio in list_of_your_audio):\n",
    "        raise ValueError(\"All audio arrays must be the same length to mix.\")\n",
    "    \n",
    "    # Mix the audio by scaling and summing\n",
    "    mixed_audio = np.zeros(length)\n",
    "    for audio, amp in zip(list_of_your_audio, amplitudes):\n",
    "        mixed_audio += amp * audio\n",
    "    \n",
    "    return mixed_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Modify your solution to Q2 so that your pipeline can generate sawtooth waves by adding harmonics based on the following equation:\n",
    "\n",
    "    $\\text{sawtooth}(f, t) = \\frac{2}{\\pi} \\sum_{k=1}^{19} \\frac{(-1)^{k+1}}{k} \\sin(2\\pi k f t)$ \n",
    "\n",
    "- **Inputs**:\n",
    "  - `frequency`: Fundamental frequency of sawtooth wave\n",
    "  - `duration`: A float representing the duration in seconds (e.g., 2.0)\n",
    "- **Output**: A NumPy array representing the audio waveform at a sample rate of 44100 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sawtooth_wave(frequency, duration, sample_rate=44100):\n",
    "    # Time array\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "    \n",
    "    # Sawtooth wave generation using harmonic summation\n",
    "    wave = (2 / np.pi) * sum(\n",
    "        ((-1) ** (k + 1)) / k * np.sin(2 * np.pi * k * frequency * t)\n",
    "        for k in range(1, 20)\n",
    "    )\n",
    "    \n",
    "    return wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B - Binary Classification\n",
    "Train a binary classification model using `scikit-learn` to distinguish between piano and drum MIDI files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unzip MIDI Files\n",
    "Extract the provided MIDI datasets:\n",
    "\n",
    "```bash\n",
    "unzip piano.zip\n",
    "unzip drums.zip\n",
    "```\n",
    "\n",
    "- `./piano`: Contains piano MIDI files (e.g., `0000.mid` to `2154.mid`)\n",
    "- `./drums`: Contains drum MIDI files (e.g., `0000.mid` to `2154.mid`)\n",
    "- Source: [Tegridy MIDI Dataset] (https://github.com/asigalov61/Tegridy-MIDI-Dataset)\n",
    "\n",
    "These folders should be extracted into the same directory as your solution file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip piano.zip\n",
    "# !unzip drums.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write functions to compute simple statistics about the files\n",
    "\n",
    "####  `get_stats()`\n",
    "\n",
    "- **Inputs**:\n",
    "  - `piano_file_paths`: List of piano MIDI file paths`\n",
    "  - `drum_file_paths`: List of drum MIDI file paths`\n",
    "- **Output**: A dictionary:\n",
    "  - `\"piano_midi_num\"`: Integer, number of piano files\n",
    "  - `\"drum_midi_num\"`: Integer, number of drum files\n",
    "  - `\"average_piano_beat_num\"`: Float, average number of beats in piano files\n",
    "  - `\"average_drum_beat_num\"`: Float, average number of beats in drum files\n",
    "- **Details**:\n",
    "  - For each file:\n",
    "    - Load with `MidiFile(file_path)`\n",
    "    - Get `ticks_per_beat` from `mid.ticks_per_beat`\n",
    "    - Compute total ticks as the maximum cumulative `msg.time` (delta time) across tracks\n",
    "    - Number of beats = (total ticks / ticks_per_beat)\n",
    "  - Compute averages, handling empty lists (return 0 if no files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_lists():\n",
    "    piano_files = sorted(glob.glob(\"./piano/*.mid\"))\n",
    "    drum_files = sorted(glob.glob(\"./drums/*.mid\"))\n",
    "    return piano_files, drum_files\n",
    "\n",
    "def get_num_beats(file_path):\n",
    "    try:\n",
    "        mid = MidiFile(file_path)\n",
    "        ticks_per_beat = mid.ticks_per_beat\n",
    "        total_ticks = 0\n",
    "        \n",
    "        for track in mid.tracks:\n",
    "            current_tick = 0\n",
    "            for msg in track:\n",
    "                current_tick += msg.time\n",
    "            total_ticks = max(total_ticks, current_tick)\n",
    "        \n",
    "        num_beats = total_ticks / ticks_per_beat if ticks_per_beat else 0\n",
    "        return num_beats\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return 0\n",
    "\n",
    "def get_stats(piano_path_list, drum_path_list):\n",
    "    piano_beat_nums = [get_num_beats(path) for path in piano_path_list]\n",
    "    drum_beat_nums = [get_num_beats(path) for path in drum_path_list]\n",
    "\n",
    "    piano_avg = np.mean(piano_beat_nums) if piano_beat_nums else 0\n",
    "    drum_avg = np.mean(drum_beat_nums) if drum_beat_nums else 0\n",
    "\n",
    "    return {\n",
    "        \"piano_midi_num\": len(piano_path_list),\n",
    "        \"drum_midi_num\": len(drum_path_list),\n",
    "        \"average_piano_beat_num\": piano_avg,\n",
    "        \"average_drum_beat_num\": drum_avg\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Implement a few simple feature functions, to compute the lowest and highest MIDI note numbers in a file, and the set of unique notes in a file\n",
    "\n",
    "`get_lowest_pitch()` and `get_highest_pitch()`\n",
    "functions to find the lowest and highest MIDI note numbers in a file\n",
    "\n",
    "- **Input**: `file_path`, a string (e.g., `\"./piano/0000.mid\"`)\n",
    "- **Output**: An integer (0–127) or `None` if no notes exist\n",
    "- **Details**:\n",
    "  - Use `MidiFile(file_path)` and scan all tracks\n",
    "  - Check `msg.type == 'note_on'` and `msg.velocity > 0` for active notes\n",
    "  - Return the minimum (`get_lowest_pitch`) or maximum (`get_highest_pitch`) `msg.note`\n",
    "\n",
    "`get_unique_pitch_num()`\n",
    "a function to count unique MIDI note numbers in a file\n",
    "\n",
    "- **Input**: `file_path`, a string\n",
    "- **Output**: An integer, the number of unique pitches\n",
    "- **Details**:\n",
    "  - Collect `msg.note` from all `'note_on'` events with `msg.velocity > 0` into a set\n",
    "  - Return the set’s length\n",
    "- **Example**: For notes `[\"C4\", \"C4\", \"G4\", \"G4\", \"A4\", \"A4\", \"G4\"]`, output is 3 (unique: C4, G4, A4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lowest_pitch(file_path):\n",
    "    try:\n",
    "        mid = MidiFile(file_path)\n",
    "        notes = [\n",
    "            msg.note for track in mid.tracks for msg in track\n",
    "            if msg.type == 'note_on' and msg.velocity > 0\n",
    "        ]\n",
    "        return min(notes) if notes else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_highest_pitch(file_path):\n",
    "    try:\n",
    "        mid = MidiFile(file_path)\n",
    "        notes = [\n",
    "            msg.note for track in mid.tracks for msg in track\n",
    "            if msg.type == 'note_on' and msg.velocity > 0\n",
    "        ]\n",
    "        return max(notes) if notes else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_unique_pitch_num(file_path):\n",
    "    try:\n",
    "        mid = MidiFile(file_path)\n",
    "        unique_notes = {\n",
    "            msg.note for track in mid.tracks for msg in track\n",
    "            if msg.type == 'note_on' and msg.velocity > 0\n",
    "        }\n",
    "        return len(unique_notes)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Implement an additional feature extraction function to compute the average MIDI note number in a file\n",
    "\n",
    "`get_average_pitch_value()`\n",
    "a function to return the average MIDI note number from a file\n",
    "\n",
    "- **Input**: `file_path`, a string\n",
    "- **Output**: A float, the average value of MIDI notes in the file\n",
    "- **Details**:\n",
    "  - Collect `msg.note` from all `'note_on'` events with `msg.velocity > 0` into a set\n",
    "- **Example**: For notes `[51, 52, 53]`, output is `52`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_pitch_value(file_path):\n",
    "    try:\n",
    "        mid = MidiFile(file_path)\n",
    "        notes = [\n",
    "            msg.note for track in mid.tracks for msg in track\n",
    "            if msg.type == 'note_on' and msg.velocity > 0\n",
    "        ]\n",
    "        return float(np.mean(notes)) if notes else 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Construct your dataset and split it into train and test sets using `scikit-learn` (most of this code is provided). Train your model to classify whether a given file is intended for piano or drums.\n",
    "\n",
    "`featureQ9()`\n",
    "\n",
    "Returns a feature vector concatenating the four features described above\n",
    "\n",
    "- **Input**: `file_path`, a string.\n",
    "- **Output**: A vector of four features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureQ9(file_path):\n",
    "    # Already implemented: this one is a freebie if you got everything above correct!\n",
    "    return [get_lowest_pitch(file_path),\n",
    "            get_highest_pitch(file_path),\n",
    "            get_unique_pitch_num(file_path),\n",
    "            get_average_pitch_value(file_path)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Creatively incorporate additional features into your classifier to make your classification more accurate.  Include comments describing your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureQ10(file_path):\n",
    "    try:\n",
    "        mid = MidiFile(file_path)\n",
    "        ticks_per_beat = mid.ticks_per_beat\n",
    "        tempo = 500000  # Default tempo = 120 BPM\n",
    "\n",
    "        # Collect notes and timing\n",
    "        notes = []\n",
    "        total_ticks = 0\n",
    "        note_count = 0\n",
    "\n",
    "        for track in mid.tracks:\n",
    "            tick_accumulator = 0\n",
    "            for msg in track:\n",
    "                tick_accumulator += msg.time\n",
    "                if msg.type == 'set_tempo':\n",
    "                    tempo = msg.tempo\n",
    "                if msg.type == 'note_on' and msg.velocity > 0:\n",
    "                    notes.append(msg.note)\n",
    "                    note_count += 1\n",
    "            total_ticks = max(total_ticks, tick_accumulator)\n",
    "\n",
    "        # Convert ticks to seconds\n",
    "        ticks_per_second = 1e6 / tempo * ticks_per_beat\n",
    "        duration_sec = total_ticks / ticks_per_second if ticks_per_second else 0\n",
    "\n",
    "        # Calculate features\n",
    "        lowest_pitch = min(notes) if notes else 0\n",
    "        highest_pitch = max(notes) if notes else 0\n",
    "        unique_pitch_count = len(set(notes))\n",
    "        average_pitch = float(np.mean(notes)) if notes else 0.0\n",
    "        note_density = note_count / duration_sec if duration_sec > 0 else 0\n",
    "\n",
    "        return [\n",
    "            lowest_pitch,\n",
    "            highest_pitch,\n",
    "            unique_pitch_count,\n",
    "            average_pitch,\n",
    "            note_count,\n",
    "            note_density,\n",
    "            duration_sec\n",
    "        ]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in file {file_path}: {e}\")\n",
    "        return [0] * 7  # Fallback feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
