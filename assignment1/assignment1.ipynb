{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7005d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Probably more imports than are really necessary...\n",
    "# import os\n",
    "# import torch\n",
    "# import torchaudio\n",
    "# from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "# from tqdm import tqdm\n",
    "# import librosa\n",
    "# import numpy as np\n",
    "# import miditoolkit\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import f1_score, average_precision_score, accuracy_score\n",
    "# import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48503b3f",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "255b620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy1(groundtruth, predictions):\n",
    "    correct = 0\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        if predictions[k] == groundtruth[k]:\n",
    "            correct += 1\n",
    "    return correct / len(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e56e40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy2(groundtruth, predictions):\n",
    "    correct = 0\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        if predictions[k] == groundtruth[k]:\n",
    "            correct += 1\n",
    "    return correct / len(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3f190f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = ['rock', 'oldies', 'jazz', 'pop', 'dance',  'blues',  'punk', 'chill', 'electronic', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2b772218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy3(groundtruth, predictions):\n",
    "    preds, targets = [], []\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        prediction = [1 if tag in predictions[k] else 0 for tag in TAGS]\n",
    "        target = [1 if tag in groundtruth[k] else 0 for tag in TAGS]\n",
    "        preds.append(prediction)\n",
    "        targets.append(target)\n",
    "    \n",
    "    mAP = average_precision_score(targets, preds, average='macro')\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6487755c",
   "metadata": {},
   "source": [
    "## Task 1: Composer classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a9fdbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot1 = \"student_files/task1_composer_classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "991509e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import miditoolkit\n",
    "# import numpy as np\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.utils import resample\n",
    "# from music21 import converter, chord\n",
    "# from collections import Counter\n",
    "\n",
    "# class model1():\n",
    "#     def __init__(self):\n",
    "#         self.model = None\n",
    "#         self.label_encoder = LabelEncoder()\n",
    "#         self.chord_vocab = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\", \"N\"]\n",
    "\n",
    "#     def extract_features(self, path):\n",
    "#         midi_path = os.path.join(dataroot1, path)\n",
    "#         try:\n",
    "#             midi = miditoolkit.MidiFile(midi_path)\n",
    "#             notes = [note for inst in midi.instruments for note in inst.notes]\n",
    "#         except:\n",
    "#             return [0.0] * (9 + len(self.chord_vocab))\n",
    "\n",
    "#         if not notes:\n",
    "#             return [0.0] * (9 + len(self.chord_vocab))\n",
    "\n",
    "#         pitches = [note.pitch for note in notes]\n",
    "#         durations = [note.end - note.start for note in notes]\n",
    "#         velocities = [note.velocity for note in notes]\n",
    "\n",
    "#         pitch_range = max(pitches) - min(pitches)\n",
    "#         density = len(notes) / (midi.max_tick + 1)\n",
    "\n",
    "#         try:\n",
    "#             score = converter.parse(midi_path)\n",
    "#             key_sig = hash(str(score.analyze('key'))) % 1000\n",
    "#             chords = score.chordify().recurse().getElementsByClass(chord.Chord)\n",
    "#             chord_roots = [c.root().name if c.isTriad() else \"N\" for c in chords]\n",
    "#             chord_count = Counter(chord_roots)\n",
    "#             chord_vector = [int(chord_count.get(name, 0) > 0) for name in self.chord_vocab]\n",
    "#         except:\n",
    "#             key_sig = 0\n",
    "#             chord_vector = [0] * len(self.chord_vocab)\n",
    "\n",
    "#         base_features = [\n",
    "#             np.mean(pitches),\n",
    "#             np.std(pitches),\n",
    "#             np.min(pitches),\n",
    "#             np.max(pitches),\n",
    "#             pitch_range,\n",
    "#             np.mean(durations),\n",
    "#             np.std(durations),\n",
    "#             np.mean(velocities),\n",
    "#             len(notes),\n",
    "#             density,\n",
    "#             key_sig\n",
    "#         ]\n",
    "\n",
    "#         return base_features + chord_vector\n",
    "\n",
    "#     def train(self, path):\n",
    "#         data = eval(open(path).read())\n",
    "#         X_raw = [self.extract_features(k) for k in data]\n",
    "#         y_raw = [data[k] for k in data]\n",
    "#         self.label_encoder.fit(y_raw)\n",
    "#         y_encoded = self.label_encoder.transform(y_raw)\n",
    "\n",
    "#         # Split into train/val (50% split)\n",
    "#         X_train, X_val, y_train, y_val = train_test_split(\n",
    "#             X_raw, y_encoded, test_size=0.5, stratify=y_encoded, random_state=42)\n",
    "\n",
    "#         # Upsample training set\n",
    "#         X_up, y_up = [], []\n",
    "#         class_labels = np.unique(y_train)\n",
    "#         max_count = max([np.sum(np.array(y_train) == cls) for cls in class_labels])\n",
    "\n",
    "#         for cls in class_labels:\n",
    "#             X_cls = [x for x, y in zip(X_train, y_train) if y == cls]\n",
    "#             y_cls = [y for y in y_train if y == cls]\n",
    "#             X_res, y_res = resample(X_cls, y_cls, replace=True, n_samples=max_count, random_state=42)\n",
    "#             X_up.extend(X_res)\n",
    "#             y_up.extend(y_res)\n",
    "\n",
    "#         print(\"✅ Upsampled training set to\", len(X_up), \"samples\")\n",
    "\n",
    "#         self.model = LGBMClassifier(max_depth=5, learning_rate=0.05, n_estimators=200)\n",
    "#         self.model.fit(X_up, y_up)\n",
    "\n",
    "#         val_acc = self.model.score(X_val, y_val)\n",
    "#         print(\"✅ Validation accuracy (50% holdout):\", val_acc)\n",
    "\n",
    "#     def predict(self, path, outpath=None):\n",
    "#         data = eval(open(path).read())\n",
    "#         X = [self.extract_features(k) for k in data]\n",
    "#         preds = self.model.predict(X)\n",
    "#         preds_decoded = self.label_encoder.inverse_transform(preds)\n",
    "#         predictions = {k: p for k, p in zip(data, preds_decoded)}\n",
    "\n",
    "#         if outpath:\n",
    "#             with open(outpath, \"w\") as f:\n",
    "#                 f.write(str(predictions) + \"\\n\")\n",
    "\n",
    "#         return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0b686224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import miditoolkit\n",
    "# import numpy as np\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from music21 import converter, chord\n",
    "# from collections import Counter\n",
    "\n",
    "# class model1():\n",
    "#     def __init__(self):\n",
    "#         self.model = None\n",
    "#         self.label_encoder = LabelEncoder()\n",
    "#         self.chord_vocab = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\", \"N\"]\n",
    "\n",
    "#     def extract_features(self, path):\n",
    "#         midi_path = os.path.join(dataroot1, path)\n",
    "#         try:\n",
    "#             midi = miditoolkit.MidiFile(midi_path)\n",
    "#             notes = [note for inst in midi.instruments for note in inst.notes]\n",
    "#         except:\n",
    "#             return [0.0] * (11 + len(self.chord_vocab))\n",
    "\n",
    "#         if not notes:\n",
    "#             return [0.0] * (11 + len(self.chord_vocab))\n",
    "\n",
    "#         pitches = [note.pitch for note in notes]\n",
    "#         durations = [note.end - note.start for note in notes]\n",
    "#         velocities = [note.velocity for note in notes]\n",
    "\n",
    "#         pitch_range = max(pitches) - min(pitches)\n",
    "#         density = len(notes) / (midi.max_tick + 1)\n",
    "\n",
    "#         try:\n",
    "#             score = converter.parse(midi_path)\n",
    "#             key_sig = hash(str(score.analyze('key'))) % 1000\n",
    "#             chords = score.chordify().recurse().getElementsByClass(chord.Chord)\n",
    "#             chord_roots = [c.root().name if c.isTriad() else \"N\" for c in chords]\n",
    "#             chord_count = Counter(chord_roots)\n",
    "#             chord_vector = [chord_count.get(name, 0) for name in self.chord_vocab]\n",
    "#         except:\n",
    "#             key_sig = 0\n",
    "#             chord_vector = [0] * len(self.chord_vocab)\n",
    "\n",
    "#         base_features = [\n",
    "#             np.mean(pitches),\n",
    "#             np.std(pitches),\n",
    "#             np.min(pitches),\n",
    "#             np.max(pitches),\n",
    "#             pitch_range,\n",
    "#             np.mean(durations),\n",
    "#             np.std(durations),\n",
    "#             np.mean(velocities),\n",
    "#             len(notes),\n",
    "#             density,\n",
    "#             key_sig\n",
    "#         ]\n",
    "\n",
    "#         return base_features + chord_vector\n",
    "\n",
    "#     def train(self, path):\n",
    "#         data = eval(open(path).read())\n",
    "#         X = [self.extract_features(k) for k in data]\n",
    "#         y = [data[k] for k in data]\n",
    "#         self.label_encoder.fit(y)\n",
    "#         y_encoded = self.label_encoder.transform(y)\n",
    "\n",
    "#         param_grid = {\n",
    "#             'max_depth': [5, 6],\n",
    "#             'learning_rate': [0.05],\n",
    "#             'n_estimators': [200]\n",
    "#         }\n",
    "\n",
    "#         grid = GridSearchCV(\n",
    "#             XGBClassifier(eval_metric='mlogloss'),\n",
    "#             param_grid,\n",
    "#             scoring='accuracy',\n",
    "#             cv=3,\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "\n",
    "#         grid.fit(X, y_encoded)\n",
    "#         self.model = grid.best_estimator_\n",
    "#         print(\"✅ GridSearch best params:\", self.model.get_params())\n",
    "#         print(\"✅ Training accuracy:\", self.model.score(X, y_encoded))\n",
    "\n",
    "#     def predict(self, path, outpath=None):\n",
    "#         data = eval(open(path).read())\n",
    "#         X = [self.extract_features(k) for k in data]\n",
    "#         preds = self.model.predict(X)\n",
    "#         preds_decoded = self.label_encoder.inverse_transform(preds)\n",
    "#         predictions = {k: p for k, p in zip(data, preds_decoded)}\n",
    "\n",
    "#         if outpath:\n",
    "#             with open(outpath, \"w\") as f:\n",
    "#                 f.write(str(predictions) + \"\\n\")\n",
    "\n",
    "#         return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ab16031e-245c-4063-bd41-df98bcfa1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ GridSearch best params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': 7, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 200, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c83a314",
   "metadata": {},
   "source": [
    "## Task 2: Sequence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cf9aaeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot2 = \"student_files/student_files/task2_next_sequence_prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "76e5e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import miditoolkit\n",
    "# import numpy as np\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "# from sklearn.feature_selection import SelectKBest, f_classif, RFECV\n",
    "# from music21 import converter\n",
    "\n",
    "# class model2():\n",
    "#     def __init__(self):\n",
    "#         self.selector = None\n",
    "#         self.model = None\n",
    "\n",
    "#     def extract_features(self, path):\n",
    "#         path = os.path.join(dataroot2, path)\n",
    "#         try:\n",
    "#             midi = miditoolkit.MidiFile(path)\n",
    "#             notes = [note for inst in midi.instruments for note in inst.notes]\n",
    "#         except:\n",
    "#             return [0.0] * 8, set(), 120, 0.0, 'unknown', 'unknown'\n",
    "\n",
    "#         if not notes:\n",
    "#             return [0.0] * 8, set(), 120, 0.0, 'unknown', 'unknown'\n",
    "\n",
    "#         pitches = [note.pitch for note in notes]\n",
    "#         durations = [note.end - note.start for note in notes]\n",
    "#         velocities = [note.velocity for note in notes]\n",
    "#         pitch_range = max(pitches) - min(pitches)\n",
    "#         density = len(notes) / (midi.max_tick + 1)\n",
    "\n",
    "#         try:\n",
    "#             score = converter.parse(path)\n",
    "#             key_sig = str(score.analyze('key'))\n",
    "#             time_sig = str(score.getTimeSignatures()[0].ratioString)\n",
    "#         except:\n",
    "#             key_sig = 'unknown'\n",
    "#             time_sig = 'unknown'\n",
    "\n",
    "#         return [\n",
    "#             np.mean(pitches),\n",
    "#             np.min(pitches),\n",
    "#             np.max(pitches),\n",
    "#             pitch_range,\n",
    "#             np.mean(durations),\n",
    "#             np.mean(velocities),\n",
    "#             len(notes),\n",
    "#             density\n",
    "#         ], set(pitches), 120, density, key_sig, time_sig\n",
    "\n",
    "#     def combine_features(self, f1, f2):\n",
    "#         x1, pitch_set1, tempo1, density1, key1, time1 = self.extract_features(f1)\n",
    "#         x2, pitch_set2, tempo2, density2, key2, time2 = self.extract_features(f2)\n",
    "#         diff = np.abs(np.array(x1) - np.array(x2)).tolist()\n",
    "#         sqdiff = ((np.array(x1) - np.array(x2)) ** 2).tolist()\n",
    "#         overlap = len(pitch_set1 & pitch_set2) / max(len(pitch_set1 | pitch_set2), 1)\n",
    "#         density_diff = abs(density1 - density2)\n",
    "#         key_match = int(key1 == key2)\n",
    "#         time_match = int(time1 == time2)\n",
    "#         return x1 + x2 + diff + sqdiff + [overlap, density_diff, key_match, time_match]\n",
    "\n",
    "#     def train(self, path):\n",
    "#         data = eval(open(path).read())\n",
    "#         X = [self.combine_features(f1, f2) for (f1, f2) in data]\n",
    "#         y = [int(data[(f1, f2)]) for (f1, f2) in data]\n",
    "\n",
    "#         param_grid = {\n",
    "#             'max_depth': [6, 7],\n",
    "#             'learning_rate': [0.05],\n",
    "#             'n_estimators': [200]\n",
    "#         }\n",
    "\n",
    "#         base_model = XGBClassifier(eval_metric='logloss')\n",
    "#         grid = GridSearchCV(base_model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "#         grid.fit(X, y)\n",
    "#         best_model = grid.best_estimator_\n",
    "\n",
    "#         print(\"✅ GridSearch best params:\", best_model.get_params())\n",
    "\n",
    "#         rfecv = RFECV(\n",
    "#             estimator=best_model,\n",
    "#             step=1,\n",
    "#             min_features_to_select=5,\n",
    "#             cv=StratifiedKFold(3),\n",
    "#             scoring='accuracy',\n",
    "#             n_jobs=-1,\n",
    "#             verbose=1\n",
    "#         )\n",
    "\n",
    "#         rfecv.fit(X, y)\n",
    "#         self.model = rfecv.estimator_\n",
    "#         self.selector = rfecv\n",
    "\n",
    "#         print(\"✅ RFECV selected\", rfecv.n_features_, \"features.\")\n",
    "#         print(\"✅ Training accuracy:\", rfecv.score(X, y))\n",
    "\n",
    "#     def predict(self, path, outpath=None):\n",
    "#         data = eval(open(path).read())\n",
    "#         X = [self.combine_features(f1, f2) for (f1, f2) in data]\n",
    "#         X_selected = self.selector.transform(X)\n",
    "\n",
    "#         preds = self.model.predict(X_selected)\n",
    "#         keys = list(data)\n",
    "#         predictions = {k: bool(p) for k, p in zip(keys, preds)}\n",
    "\n",
    "#         if outpath:\n",
    "#             with open(outpath, 'w') as f:\n",
    "#                 f.write(str(predictions) + \"\\n\")\n",
    "#         return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab036c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f36bf2cf",
   "metadata": {},
   "source": [
    "## Task 3: Audio classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b94c0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"student_files/task3_audio_classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6b0fa649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "TAGS = ['rock', 'oldies', 'jazz', 'pop', 'dance', 'blues', 'punk', 'chill', 'electronic', 'country']\n",
    "SAMPLE_RATE = 16000\n",
    "N_MELS = 64\n",
    "N_CLASSES = len(TAGS)\n",
    "AUDIO_DURATION = 10  # seconds\n",
    "BATCH_SIZE = 32\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, meta, root, train=False, preload=False):\n",
    "        self.meta = meta\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.paths = list(meta.keys())\n",
    "        self.labels = [meta[k] for k in self.paths]\n",
    "        self.mel = MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=N_MELS)\n",
    "        self.db = AmplitudeToDB()\n",
    "        self.preload = preload\n",
    "        self.pathToFeat = {}\n",
    "\n",
    "        if preload:\n",
    "            for path in tqdm(self.paths, desc=\"Preloading features\"):\n",
    "                full_path = os.path.join(self.root, path)\n",
    "                waveform, sr = librosa.load(full_path, sr=SAMPLE_RATE)\n",
    "                waveform = np.array([waveform])\n",
    "                pad_len = max(0, SAMPLE_RATE * AUDIO_DURATION - waveform.shape[1])\n",
    "                if pad_len > 0:\n",
    "                    waveform = F.pad(torch.tensor(waveform), (0, pad_len))\n",
    "                else:\n",
    "                    waveform = torch.tensor(waveform[:, :SAMPLE_RATE * AUDIO_DURATION])\n",
    "                mel_spec = self.db(self.mel(waveform)).squeeze(0)\n",
    "                self.pathToFeat[path] = mel_spec\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        if self.preload:\n",
    "            mel_spec = self.pathToFeat[path]\n",
    "        else:\n",
    "            full_path = os.path.join(self.root, path)\n",
    "            waveform, sr = librosa.load(full_path, sr=SAMPLE_RATE)\n",
    "            waveform = np.array([waveform])\n",
    "            pad_len = max(0, SAMPLE_RATE * AUDIO_DURATION - waveform.shape[1])\n",
    "            if pad_len > 0:\n",
    "                waveform = F.pad(torch.tensor(waveform), (0, pad_len))\n",
    "            else:\n",
    "                waveform = torch.tensor(waveform[:, :SAMPLE_RATE * AUDIO_DURATION])\n",
    "            mel_spec = self.db(self.mel(waveform)).squeeze(0)\n",
    "\n",
    "        if self.train:\n",
    "            if torch.rand(1).item() < 0.5:\n",
    "                mel_spec = mel_spec + 0.01 * torch.randn_like(mel_spec)\n",
    "            if torch.rand(1).item() < 0.5:\n",
    "                mel_spec = torch.roll(mel_spec, shifts=np.random.randint(-10, 10), dims=-1)\n",
    "\n",
    "        multi_hot = torch.tensor([1 if tag in self.meta[path] else 0 for tag in TAGS], dtype=torch.float32)\n",
    "        smoothed = (1 - LABEL_SMOOTHING) * multi_hot + LABEL_SMOOTHING / N_CLASSES\n",
    "        return mel_spec.unsqueeze(0), smoothed, path\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * (N_MELS // 8) * (801 // 8), 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, N_CLASSES))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, model, lr=1e-4):\n",
    "        self.model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=15)\n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "    def train(self, loader_train, loader_val, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            for x, y, _ in tqdm(loader_train, desc=f\"Epoch {epoch+1}\"):\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                out = self.model(x)\n",
    "                loss = self.criterion(out, y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            self.scheduler.step()\n",
    "            print(f\"[Epoch {epoch+1}] Loss: {total_loss / len(loader_train):.4f}\")\n",
    "\n",
    "    def evaluate(self, loader, threshold=0.5, outpath=None):\n",
    "        self.model.eval()\n",
    "        predictions = {}\n",
    "        targets = []\n",
    "        preds_raw = []\n",
    "        paths = []\n",
    "        with torch.no_grad():\n",
    "            for x, y, ps in loader:\n",
    "                x = x.to(self.device)\n",
    "                out = self.model(x).cpu()\n",
    "                preds_raw.append(out)\n",
    "                targets.append(y)\n",
    "                paths.extend(ps)\n",
    "\n",
    "        preds_raw = torch.cat(preds_raw)\n",
    "        targets = torch.cat(targets)\n",
    "\n",
    "        thresholds = []\n",
    "        for i in range(N_CLASSES):\n",
    "            precision, recall, thresh = precision_recall_curve(targets[:, i], preds_raw[:, i])\n",
    "            f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "            best_thresh = thresh[f1[:-1].argmax()] if len(thresh) > 0 else 0.5\n",
    "            thresholds.append(best_thresh)\n",
    "\n",
    "        for i in range(len(paths)):\n",
    "            pred_vec = (preds_raw[i] > torch.tensor(thresholds).to(preds_raw.device)).float()\n",
    "            predictions[paths[i]] = [TAGS[j] for j in range(N_CLASSES) if pred_vec[j] > 0.5]\n",
    "\n",
    "        mAP = average_precision_score(targets, preds_raw, average='macro')\n",
    "        print(\"Validation mAP:\", mAP)\n",
    "\n",
    "        if outpath:\n",
    "            with open(outpath, 'w') as f:\n",
    "                f.write(str(predictions) + \"\\n\")\n",
    "        else:\n",
    "            return predictions, mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4fddf329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92023e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loaders():\n",
    "    def __init__(self, train_path, test_path, split_ratio=0.8, seed=0):\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        meta_train = eval(open(train_path, 'r').read())\n",
    "        l_test = eval(open(test_path, 'r').read())\n",
    "        meta_test = {x: [] for x in l_test}\n",
    "\n",
    "        full_train = list(meta_train.items())\n",
    "        random.shuffle(full_train)\n",
    "        meta_train = dict(full_train)\n",
    "\n",
    "        all_train = AudioDataset(meta_train, root, train=True, preload=True)\n",
    "        test_set = AudioDataset(meta_test, root, preload=False)\n",
    "\n",
    "        # Split into train + valid\n",
    "        total_len = len(all_train)\n",
    "        train_len = int(total_len * split_ratio)\n",
    "        valid_len = total_len - train_len\n",
    "        train_set, valid_set = torch.utils.data.random_split(all_train, [train_len, valid_len])\n",
    "\n",
    "        self.loaderTrain = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "        self.loaderValid = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "        self.loaderTest  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c50c5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohh ok let's try this. This code is over the baseline on validation set, so i want you to use this to run prediction on test set: import os\n",
    "# import torch\n",
    "# import torchaudio\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "# from sklearn.metrics import average_precision_score\n",
    "# import librosa\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# TAGS = ['rock', 'oldies', 'jazz', 'pop', 'dance', 'blues', 'punk', 'chill', 'electronic', 'country']\n",
    "# SAMPLE_RATE = 16000\n",
    "# N_MELS = 64\n",
    "# N_CLASSES = len(TAGS)\n",
    "# AUDIO_DURATION = 10  # seconds\n",
    "# BATCH_SIZE = 32\n",
    "\n",
    "# # --- Dataset with optional Preload and Augmentation ---\n",
    "# class AudioDataset(Dataset):\n",
    "#     def __init__(self, meta, root, train=False, preload=False):\n",
    "#         self.meta = meta\n",
    "#         self.root = root\n",
    "#         self.train = train\n",
    "#         self.paths = list(meta.keys())\n",
    "#         self.labels = [meta[k] for k in self.paths]\n",
    "#         self.mel = MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=N_MELS)\n",
    "#         self.db = AmplitudeToDB()\n",
    "#         self.preload = preload\n",
    "#         self.pathToFeat = {}\n",
    "\n",
    "#         if preload:\n",
    "#             for path in tqdm(self.paths, desc=\"Preloading features\"):\n",
    "#                 full_path = os.path.join(self.root, path)\n",
    "#                 waveform, sr = librosa.load(full_path, sr=SAMPLE_RATE)\n",
    "#                 waveform = np.array([waveform])\n",
    "#                 pad_len = max(0, SAMPLE_RATE * AUDIO_DURATION - waveform.shape[1])\n",
    "#                 if pad_len > 0:\n",
    "#                     waveform = F.pad(torch.tensor(waveform), (0, pad_len))\n",
    "#                 else:\n",
    "#                     waveform = torch.tensor(waveform[:, :SAMPLE_RATE * AUDIO_DURATION])\n",
    "#                 mel_spec = self.db(self.mel(waveform)).squeeze(0)\n",
    "#                 self.pathToFeat[path] = mel_spec\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         path = self.paths[idx]\n",
    "#         if self.preload:\n",
    "#             mel_spec = self.pathToFeat[path]\n",
    "#         else:\n",
    "#             full_path = os.path.join(self.root, path)\n",
    "#             waveform, sr = librosa.load(full_path, sr=SAMPLE_RATE)\n",
    "#             waveform = np.array([waveform])\n",
    "#             pad_len = max(0, SAMPLE_RATE * AUDIO_DURATION - waveform.shape[1])\n",
    "#             if pad_len > 0:\n",
    "#                 waveform = F.pad(torch.tensor(waveform), (0, pad_len))\n",
    "#             else:\n",
    "#                 waveform = torch.tensor(waveform[:, :SAMPLE_RATE * AUDIO_DURATION])\n",
    "#             mel_spec = self.db(self.mel(waveform)).squeeze(0)\n",
    "\n",
    "#         if self.train:\n",
    "#             if torch.rand(1).item() < 0.5:\n",
    "#                 mel_spec = mel_spec + 0.01 * torch.randn_like(mel_spec)\n",
    "#             if torch.rand(1).item() < 0.5:\n",
    "#                 mel_spec = torch.roll(mel_spec, shifts=np.random.randint(-10, 10), dims=-1)\n",
    "\n",
    "#         multi_hot = torch.tensor([1 if tag in self.labels[idx] else 0 for tag in TAGS], dtype=torch.float32)\n",
    "#         return mel_spec.unsqueeze(0), multi_hot, path\n",
    "\n",
    "# # --- Loaders ---\n",
    "# class Loaders:\n",
    "#     def __init__(self, train_path, test_path, root):\n",
    "#         import random\n",
    "#         torch.manual_seed(0)\n",
    "#         random.seed(0)\n",
    "\n",
    "#         meta_train = eval(open(train_path, 'r').read())\n",
    "#         test_files = eval(open(test_path, 'r').read())\n",
    "#         meta_test = {x: [] for x in test_files}\n",
    "\n",
    "#         full_train = list(meta_train.items())\n",
    "#         split = int(0.9 * len(full_train))\n",
    "#         random.shuffle(full_train)\n",
    "#         meta_train, meta_valid = dict(full_train[:split]), dict(full_train[split:])\n",
    "\n",
    "#         self.loaderTrain = DataLoader(AudioDataset(meta_train, root, train=True, preload=True), batch_size=BATCH_SIZE, shuffle=True)\n",
    "#         self.loaderValid = DataLoader(AudioDataset(meta_valid, root, preload=True), batch_size=BATCH_SIZE)\n",
    "#         self.loaderTest = DataLoader(AudioDataset(meta_test, root, preload=False), batch_size=BATCH_SIZE)\n",
    "\n",
    "# # --- CNN Model ---\n",
    "# class CNNClassifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 16, 3, padding=1),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2))\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(16, 32, 3, padding=1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2))\n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv2d(32, 64, 3, padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2))\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(64 * (N_MELS // 8) * (801 // 8), 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(256, N_CLASSES))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.conv3(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         return self.fc(x)\n",
    "\n",
    "# # --- Training and Evaluation ---\n",
    "# class Pipeline:\n",
    "#     def __init__(self, model, lr=1e-4):\n",
    "#         self.model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "#         self.criterion = nn.BCEWithLogitsLoss()\n",
    "#         self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "#         self.device = next(model.parameters()).device\n",
    "\n",
    "#     def train(self, loader, num_epochs):\n",
    "#         for epoch in range(num_epochs):\n",
    "#             self.model.train()\n",
    "#             total_loss = 0\n",
    "#             for x, y, _ in tqdm(loader, desc=f\"Epoch {epoch+1}\"):\n",
    "#                 x, y = x.to(self.device), y.to(self.device)\n",
    "#                 out = self.model(x)\n",
    "#                 loss = self.criterion(out, y)\n",
    "#                 self.optimizer.zero_grad()\n",
    "#                 loss.backward()\n",
    "#                 self.optimizer.step()\n",
    "#                 total_loss += loss.item()\n",
    "#             print(f\"[Epoch {epoch+1}] Loss: {total_loss / len(loader):.4f}\")\n",
    "\n",
    "#     def evaluate(self, loader, outpath=None, top_k=2):\n",
    "#         self.model.eval()\n",
    "#         predictions = {}\n",
    "#         targets = []\n",
    "#         preds_raw = []\n",
    "#         paths = []\n",
    "#         with torch.no_grad():\n",
    "#             for x, y, ps in loader:\n",
    "#                 x = x.to(self.device)\n",
    "#                 out = self.model(x).cpu()\n",
    "#                 preds_raw.append(out)\n",
    "#                 targets.append(y)\n",
    "#                 paths.extend(ps)\n",
    "\n",
    "#         preds_raw = torch.cat(preds_raw)\n",
    "#         targets = torch.cat(targets)\n",
    "\n",
    "#         for i in range(len(paths)):\n",
    "#             topk = preds_raw[i].topk(top_k).indices\n",
    "#             predictions[paths[i]] = [TAGS[j] for j in topk]\n",
    "\n",
    "#         if outpath:\n",
    "#             with open(outpath, 'w') as f:\n",
    "#                 f.write(str(predictions) + \"\\n\")\n",
    "#         else:\n",
    "#             mAP = average_precision_score(targets, preds_raw, average='macro')\n",
    "#             print(\"Validation mAP:\", mAP)\n",
    "#             return predictions, mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87197d0",
   "metadata": {},
   "source": [
    "## Run everything..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9708d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run1():\n",
    "#     model = model1()\n",
    "#     model.train(dataroot1 + \"/train.json\")\n",
    "#     train_preds = model.predict(dataroot1 + \"/train.json\")\n",
    "#     test_preds = model.predict(dataroot1 + \"/test.json\", \"predictions1.json\")\n",
    "#     train_labels = eval(open(dataroot1 + \"/train.json\").read())\n",
    "#     acc1 = accuracy1(train_labels, train_preds)\n",
    "#     print(\"Task 1 training accuracy = \" + str(acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9cb50b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run2():\n",
    "#     model = model2()\n",
    "#     model.train(dataroot2 + \"/train.json\")\n",
    "#     train_preds = model.predict(dataroot2 + \"/train.json\")\n",
    "#     test_preds = model.predict(dataroot2 + \"/test.json\", \"predictions2.json\")\n",
    "    \n",
    "#     train_labels = eval(open(dataroot2 + \"/train.json\").read())\n",
    "#     acc2 = accuracy2(train_labels, train_preds)\n",
    "#     print(\"Task 2 training accuracy = \" + str(acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3dbe7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run3():\n",
    "    loaders = Loaders(root + \"/train.json\", root + \"/test.json\")\n",
    "    model = CNNClassifier()\n",
    "    pipeline = Pipeline(model, 1e-4)\n",
    "    \n",
    "    pipeline.train(loaders.loaderTrain, loaders.loaderValid, 5)\n",
    "    train_preds, train_mAP = pipeline.evaluate(loaders.loaderTrain, 0.5)\n",
    "    valid_preds, valid_mAP = pipeline.evaluate(loaders.loaderValid, 0.5)\n",
    "    test_preds, _ = pipeline.evaluate(loaders.loaderTest, 0.5, \"predictions3.json\")\n",
    "    \n",
    "    all_train = eval(open(root + \"/train.json\").read())\n",
    "    for k in valid_preds:\n",
    "        # We split our training set into train+valid\n",
    "        # so need to remove validation instances from the training set for evaluation\n",
    "        all_train.pop(k)\n",
    "    acc3 = accuracy3(all_train, train_preds)\n",
    "    print(\"Task 3 training mAP = \" + str(acc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "458d6570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111600f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f0286c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "876da745",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[103], line 2\u001b[0m, in \u001b[0;36mrun3\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun3\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     loaders \u001b[38;5;241m=\u001b[39m \u001b[43mLoaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/train.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/test.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m CNNClassifier()\n\u001b[1;32m      4\u001b[0m     pipeline \u001b[38;5;241m=\u001b[39m Pipeline(model, \u001b[38;5;241m1e-4\u001b[39m)\n",
      "Cell \u001b[0;32mIn[99], line 5\u001b[0m, in \u001b[0;36mLoaders.__init__\u001b[0;34m(self, train_path, test_path, split_ratio, seed)\u001b[0m\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m      7\u001b[0m meta_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[38;5;28mopen\u001b[39m(train_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m      8\u001b[0m l_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[38;5;28mopen\u001b[39m(test_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "run3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
